\resheading{Professional Experience}
  \begin{itemize}[leftmargin=*]
  \item
      \ressubsingleline{\href{https://www.apple.com/careers/us/machine-learning-and-ai.html}{Apple (Beijing) - Video Engineering}}{Computer Vision Algorithms Intern}{2021.05.10 -- 2021.09.30}
      {\small
      \begin{itemize}

      \begin{spacing}{1.2}
        \item Research, development and optimization of Video Instance Segmentation(VIS/MOTS) algorithms.
      \end{spacing}
      \end{itemize}
      }

    \vspace{-1.5em}
    \item
      \ressubsingleline{\href{https://ailab.bytedance.com/}{ByteDance (Beijing) - Visual Computing Group}}{Algorithms Intern}{2021.01.11 -- 2021.04.30}
      {\small
      \begin{itemize}

      \begin{spacing}{1.2}
        \item Collaborated with \href{https://scholar.google.com/citations?user=iHoGTt4AAAAJ}{Dr. Qi She} and Ads Core team, responsible for Conversion Rate (CVR) model in online advertisement recommendation scenarios. We propose an Online Orthogonal Gradient Descent (O2GD) optimizer to address the periodic degeneration problems in Ad. System.
        \item Proposed and implemented FTRML, MADGrad, FTML, AdaMom optimizer solutions in the large scale distributed parameter server for ML training to promote advertisement AUC metric with 0.1\% improvment.
        
      \end{spacing}
      \end{itemize}
      }

    \vspace{-1.5em}
    \item
      \ressubsingleline{\href{https://www.xyzrobotics.ai}{XYZ Robotics (Shanghai)}}{Vision Algorithms Core Intern}{2019.01 -- 2019.08}
      {\small
      \begin{itemize}

      \begin{spacing}{1.2}
        \item Awarded with \href{https://qihao-huang.github.io/archive/HQH-XYZ-intern-award.pdf}{\textbf{Outstanding Intern of the Year}}, worked with \href{http://www.cs.cmu.edu/~jiajiz/}{Dr. Jiaji Zhou} and \href{http://people.csail.mit.edu/peterkty/}{Dr. Peter Yu}. Led by MIT-Princeton winner team of \href{https://arc.cs.princeton.edu/}{Amazon Robotics Challenge} for logistic automation solution driven by visual perception. \href{https://www.xyzrobotics.ai/piece-picking-station/}{\textbf{[Details Link]}}.
   
        % \item 负责\textbf{紧密堆放物品}场景下的小件拣选研发，在团队于 \href{https://arc.cs.princeton.edu/}{Amazon Robotics Challenge MIT-Princeton Winning Solution} 混杂场景的基础上，扩展至紧密堆放场景。为解决紧密堆放时吸取点预测无法准确定位到物体中心的问题，我们以边缘预测作为约束。此外，我们通过 RGB-DDD 融合输入的方式，提高由相机摆放导致的远侧物体大小不一致下的预测成功率。在欧莱雅、天猫合作提供的30余种不同颜色、纹理、角度、大小的物体、多种堆叠方式中实现100\%的密集识别测试成功率。此项目获得团队年度实习生的额外奖励。
        
        \item Responsible for enhancing \textbf{piece picking} project by incorporating segmentation RGB-DDD network for densely-packed homogenous cases in clutter. Tested successfully with more than 30 kinds of cases provided by L'Oréal and Tmall.
        
        \item Responsible for implementation of \textbf{robotic depalletizing} project by tuning Mask R-CNN in the industrial field. It integrates RGB-D sensors to locate a wide variety of boxes and interleaving motion and vision to maximize pick rates. Also rendered synthetic dataset by Blender; Calibrated RealSense RGB-D and ZED stereo cameras.
        
        % 负责\textbf{整箱拆垛}的新项目研发，将垛箱俯视图识别转换为实例分割问题，扩展 Mask R-CNN 作为视觉核心。由于新业务的特殊性，于某市医药企业自动化地采集仓库搬运数据。在本地服务器上编写 Labelme 公网端口，众包数据团队标注GT。考虑到采集到的数据规模较小，使用 Blender 渲染引擎 Python 接口，合成不同纹理、大小、随机噪声的垛箱俯视图以增加多样性。与硬件团队合作，在企业内部 ABB 机器人平台上调整、部署。过程中，学习使用 RealSense RGB-D 相机的 PCL C++ 接口，棋盘标定等。在此基础之上，此项目于2020年成为公司核心解决方案。 

      \end{spacing}
      \end{itemize}
      }
  \vspace{-1.5em}
  \end{itemize}
